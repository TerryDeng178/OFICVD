# v4.0.5 P0 优化实施总结

> **日期**: 2025-11-07  
> **优先级**: P0（立即修复，影响结论正确性）

---

## 执行摘要

基于测试报告发现的"双 Sink 对齐"计数不一致问题（差异 151.14%），实施了 P0 优化，解决根因：**时间限时跑 + --watch 导致处理吞吐差异**。

---

## 已完成的 P0 优化项

### ✅ P0-A: 回放场景移除 --watch，改为批处理模式

**问题**: 
- Orchestrator 以 `--minutes` 控制整体时长，同时 Signal Server 始终用 `--watch` 持续拉流
- SQLite 落库比 JSONL 写文件慢 → 在相同时长内处理的条目数不同
- 导致总数差 150%+，但强信号占比仅差 0.76%（口径一致，吞吐不同）

**解决方案**: 
- 回放场景（`V13_REPLAY_MODE=1` 或配置文件名包含 `replay`）移除 `--watch`
- 改为批处理模式：处理完固定文件集后退出，而不是持续拉流
- 实时场景保持 `--watch` 持续监控新文件

**代码位置**: `orchestrator/run.py` 第 1028-1034 行

**修改内容**:
```python
# P0: 回放场景移除 --watch，改为批处理模式（跑到数据耗尽）
signal_cmd = ["mcp.signal_server.app", "--config", str(config_path), "--input", str(features_dir), "--sink", sink_kind, "--out", str(output_dir)]
if not is_replay_mode:
    # 实时场景：使用 --watch 持续监控新文件
    signal_cmd.insert(-2, "--watch")
```

**验证**: ✅ 已实现，回放场景不再使用 `--watch`

---

### ✅ P0-B: 验证脚本改为重叠窗口对齐

**问题**: 
- 验证脚本只按相同索引位比较分钟节律，未考虑吞吐差导致的时间片不重叠
- 现实现无法处理 JSONL 和 SQLite 处理速度不同导致的分钟键差异

**解决方案**: 
- 取 JSONL/SQLite 分钟键的交集，对交集窗口求和再比对
- 避免吞吐差导致的时间片不重叠
- 对交集窗口汇总值使用核心计数类 5% 阈值
- 逐分钟对比使用 10% 阈值（非核心计数类）

**代码位置**: `scripts/verify_sink_parity.sh` 第 173-231 行

**修改内容**:
```bash
# P0: 取分钟键的交集，避免吞吐差导致的时间片不重叠
jsonl_minute_keys = {item.get("minute") for item in jsonl_per_minute}
sqlite_minute_keys = {item.get("minute") for item in sqlite_per_minute}
overlap_keys = sorted(jsonl_minute_keys & sqlite_minute_keys)

# 对交集窗口求和
jsonl_overlap_total = sum(jsonl_minute_map.get(k, 0) for k in overlap_keys)
sqlite_overlap_total = sum(sqlite_minute_map.get(k, 0) for k in overlap_keys)

# 对比交集窗口汇总值（使用核心计数类 5% 阈值）
```

**验证**: ✅ 已实现，重叠窗口对齐逻辑已添加

---

### ✅ P0-C: 修正文档中的自相矛盾表述

**问题**: 
- 报告表格显示多项超 5% 阈值，但结论写"所有指标差异在容忍范围内"
- 自相矛盾，影响结论正确性

**解决方案**: 
- 统一为"计数超阈值，比例通过，疑似处理量不一致"
- 明确说明：Total/Buy/Sell/Strong 计数差异超过 5% 阈值，但 StrongRatio 差异仅 0.76%（在 10% 阈值内），说明统计口径一致，疑似处理量不一致导致

**代码位置**: `reports/v4.0.5-测试验证报告.md` 第 55-58 行

**修改内容**:
```markdown
**验证要点**:
- ✅ 核心计数类使用 5% 阈值
- ✅ 比率类使用 10% 阈值
- ⚠️ **计数超阈值，比例通过**: Total/Buy/Sell/Strong 计数差异超过 5% 阈值，但 StrongRatio 差异仅 0.76%（在 10% 阈值内），说明统计口径一致，疑似处理量不一致导致
```

**验证**: ✅ 已修正，文档表述一致

---

## P1 优化项（部分完成）

### ✅ P1-A: SQLite Sink 性能优化

**问题**: SQLite 落库比 JSONL 写文件慢，导致吞吐差

**解决方案**: 
- 启用 `PRAGMA temp_store=MEMORY`（使用内存临时存储）
- 增大缓存 `PRAGMA cache_size=-20000`（约 80MB）
- 已有 `PRAGMA journal_mode=WAL` 和 `PRAGMA synchronous=NORMAL`

**代码位置**: `src/alpha_core/signals/core_algo.py` 第 143-148 行

**修改内容**:
```python
# P1: SQLite 性能优化，减少"吞吐差"
self.conn.execute("PRAGMA journal_mode=WAL;")
self.conn.execute("PRAGMA synchronous=NORMAL;")
self.conn.execute("PRAGMA temp_store=MEMORY;")
self.conn.execute("PRAGMA cache_size=-20000;")  # 约 80MB
```

**验证**: ✅ 已实现

---

### ✅ P1-B: verify_sink_parity.sh 的可移植性

**问题**: 
- 使用 GNU `find -printf` 取最新文件，macOS 上不兼容
- CI 已覆盖 Ubuntu/Windows，但本地跑会踩坑

**解决方案**: 
- 改用 Python `glob+mtime` 选文件，避免平台差异
- 使用 Python 内联脚本替代 `find -printf`

**代码位置**: `scripts/verify_sink_parity.sh` 第 44-49 行、第 74-82 行

**修改内容**:
```bash
# P1: 使用 Python glob+mtime 选文件，避免平台差异
JSONL_REPORT=$(python3 <<EOF
import glob
import os
reports = glob.glob("${PROJECT_ROOT}/logs/report/summary_*.json")
if reports:
    latest = max(reports, key=os.path.getmtime)
    print(latest)
EOF
)
```

**验证**: ✅ 已实现

---

## 待完成的 P1 优化项

### ⏳ P1-C: 报表补充"处理吞吐"与"重叠窗口摘要"

**计划**: 
- 在 Reporter 输出里新增：`rows_processed`, `files_read`, `first_minute`, `last_minute`
- 输出"交集窗口计数汇总"以辅助脚本快速对齐

**状态**: 待实施

---

### ⏳ P1-D: CI Job 通过与失败的"证据包"标准化

**计划**: 
- 验证脚本把对比结果写成 `parity_diff.json`（含每项 diff、交集窗口范围、阈值与是否通过）
- 随报告一并作为 artifact 上传

**状态**: 待实施

---

## 测试验证

### 验证方法

1. **回放场景移除 --watch**: 
   - 设置 `V13_REPLAY_MODE=1`
   - 运行 `orchestrator.run`，检查 `signal_cmd` 中不包含 `--watch`

2. **重叠窗口对齐**: 
   - 运行 `verify_sink_parity.sh`
   - 检查输出中是否显示"重叠窗口"和"重叠窗口汇总"

3. **文档修正**: 
   - 检查 `v4.0.5-测试验证报告.md` 中的验证要点是否一致

---

## 结论

✅ **所有 P0 优化项已完成**

- ✅ 回放场景移除 --watch，改为批处理模式
- ✅ 验证脚本改为重叠窗口对齐
- ✅ 修正文档中的自相矛盾表述
- ✅ SQLite 性能优化（P1，提前完成）
- ✅ 脚本可移植性优化（P1，提前完成）

**下一步**: 
- 实施 P1-C（报表补充处理吞吐）
- 实施 P1-D（CI 证据包标准化）
- 运行测试验证所有优化项

---

**完成时间**: 2025-11-07  
**状态**: ✅ P0 全部完成，P1 部分完成

