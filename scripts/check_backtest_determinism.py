#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TASK-B2: å›æµ‹ç¡®å®šæ€§æ ¡éªŒå™¨

æ£€æŸ¥ç›¸åŒé…ç½®å’Œè¾“å…¥çš„å¤šæ¬¡è¿è¡Œç»“æœæ˜¯å¦å“ˆå¸Œä¸€è‡´

ä½¿ç”¨æ–¹æ³•:
python scripts/check_backtest_determinism.py <run_dir1> <run_dir2> [<run_dir3> ...]
"""

import argparse
import json
import hashlib
from pathlib import Path
from typing import Dict, Any
import sys

def calculate_file_hash(file_path: Path) -> str:
    """è®¡ç®—æ–‡ä»¶å†…å®¹çš„SHA256å“ˆå¸Œ"""
    if not file_path.exists():
        return ""

    hasher = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hasher.update(chunk)
    return hasher.hexdigest()

def load_json_file(file_path: Path) -> Dict[str, Any]:
    """åŠ è½½JSONæ–‡ä»¶ï¼Œæ’é™¤éç¡®å®šæ€§å­—æ®µ"""
    if not file_path.exists():
        return {}

    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # æ’é™¤éç¡®å®šæ€§å­—æ®µ
    exclude_fields = ['created_at', 'git.commit', 'perf.duration_s', 'perf.memory_gib']
    for field in exclude_fields:
        keys = field.split('.')
        current = data
        for key in keys[:-1]:
            if key in current:
                current = current[key]
            else:
                break
        else:
            if keys[-1] in current:
                del current[keys[-1]]

    return data

def calculate_run_hash(run_dir: Path) -> str:
    """è®¡ç®—æ•´ä¸ªè¿è¡Œç»“æœçš„ç»¼åˆå“ˆå¸Œ"""
    hashes = []

    # å“ˆå¸Œå„ä¸ªäº§ç‰©æ–‡ä»¶
    files_to_hash = ['signals.jsonl', 'trades.jsonl', 'pnl_daily.jsonl']
    for filename in files_to_hash:
        file_path = run_dir / filename
        if file_path.exists():
            hashes.append(calculate_file_hash(file_path))

    # å“ˆå¸Œrun_manifestï¼ˆæ’é™¤æ—¶é—´æˆ³ç­‰éç¡®å®šæ€§å­—æ®µï¼‰
    manifest_file = run_dir / "run_manifest.json"
    if manifest_file.exists():
        manifest = load_json_file(manifest_file)
        # å¯¹æ’åºåçš„JSONè®¡ç®—å“ˆå¸Œ
        manifest_str = json.dumps(manifest, sort_keys=True, ensure_ascii=False)
        hashes.append(hashlib.sha256(manifest_str.encode('utf-8')).hexdigest())

    # è®¡ç®—ç»¼åˆå“ˆå¸Œ
    combined = '|'.join(hashes)
    return hashlib.sha256(combined.encode('utf-8')).hexdigest()

def main():
    parser = argparse.ArgumentParser(description="TASK-B2: Backtest Determinism Checker")
    parser.add_argument("run_dirs", nargs='+', type=str,
                       help="Backtest run directories to compare")
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="Show detailed hash information")

    args = parser.parse_args()

    run_dirs = [Path(d) for d in args.run_dirs]

    # æ£€æŸ¥ç›®å½•å­˜åœ¨æ€§
    for run_dir in run_dirs:
        if not run_dir.exists():
            print(f"ERROR: Run directory not found: {run_dir}")
            return 1

    print("=== TASK-B2: Backtest Determinism Check ===")
    print(f"Comparing {len(run_dirs)} runs:")
    for i, run_dir in enumerate(run_dirs, 1):
        print(f"  Run {i}: {run_dir}")
    print()

    # è®¡ç®—å„è¿è¡Œçš„å“ˆå¸Œ
    run_hashes = []
    for run_dir in run_dirs:
        run_hash = calculate_run_hash(run_dir)
        run_hashes.append(run_hash)

        if args.verbose:
            print(f"Hash for {run_dir.name}: {run_hash}")

    # æ£€æŸ¥å“ˆå¸Œä¸€è‡´æ€§
    first_hash = run_hashes[0]
    all_match = all(h == first_hash for h in run_hashes)

    print(f"Results:")
    print(f"  Reference hash: {first_hash}")

    for i, (run_dir, run_hash) in enumerate(zip(run_dirs, run_hashes), 1):
        status = "âœ“ MATCH" if run_hash == first_hash else "âœ— MISMATCH"
        print(f"  Run {i} ({run_dir.name}): {status}")

    print()
    if all_match:
        print("ğŸ‰ DETERMINISM VERIFIED: All runs produced identical results!")
        return 0
    else:
        print("âŒ DETERMINISM FAILED: Runs produced different results!")
        print("This indicates non-deterministic behavior in the backtest system.")
        return 1

if __name__ == "__main__":
    sys.exit(main())
